---
title: "Final"
author: "Vriz Gian Luca"
date: "2023-07-20"
output: pdf_document
---

#Libraries

The project includes the following libraries.

```{r, warning=FALSE}
library(exuber)
library(readr)
library(bsts)
library(dplyr)
library(car)
library(DescTools)
library(ModelMetrics)
library(fDMA)
library(hrbrthemes)
library(ggpmisc)
library(Rlibeemd)
library(xtable)
library(dtw)
library(lmtest)
library(Metrics)
library(tseries)
library(urca)
library(vars)
library(factoextra)
library(ggfortify)
library(modelr)
library(readxl)
library(epiDisplay)
library(blorr)
library(gridExtra)
library(oddsratio)
library(tictoc)
library(Rbeast)
library(psymonitor)
library(bbdetection)
library(devtools)
library(rbmi)
library(dplyr)
library(dqshiny)
library(ggplot2)
library(ghyp)
library(lubridate)
library(strucchange)
library(changepoint)
library(Rssa)
library(tidyr)
library(qcc)
library(corrplot)
library(zoo)
library(rugarch)
library(cpm)
library(visreg)
library(urca)
library(glmnet)
library(psych)
add_class <- function(x, ...) {
  class(x) <- append(c(...), class(x))
  x
}
```

#Bubbles

Firstly, the data generation of bubbles phenomena is outlined.

```{r, warning=FALSE}
#install_url('https://cran.r-project.org/src/contrib/Archive/psymonitor/psymonitor_0.0.2.tar.gz')
#install_url('https://cran.r-project.org/src/contrib/Archive/dqshiny/dqshiny_0.0.4.tar.gz')
add_class <- function(x, ...) {
  class(x) <- append(c(...), class(x))
  x
}
#DATA
#https://rdrr.io/rforge/rugarch/man/sp500ret.html
#https://rdrr.io/rforge/rugarch/man/dmbp.html
data("sp500ret")
data_garch = sp500ret*100
#GARCH
spec <- ugarchspec(variance.model = list(model = "eGARCH",garchOrder = c(1,1))
                   ,distribution.model="ghyp")
fit = ugarchfit(data = data_garch , spec = spec)
#Residuals
garch_resid <- residuals(fit, standardize = FALSE)
#Extract standardized residuals
garch_resid_std <- residuals(fit, standardize = TRUE)
#Standardized residuals to be used in ugarchsim()
custom_dist = list(
  name = "sample",
  distfit = matrix(garch_resid_std,  ncol = 1)
)
m_ <- fit@model$maxOrder
garch_sim <- ugarchsim(fit, 
                       n.sim = length(garch_resid_std),
                       m.sim = 1, 
                       presigma = tail(fit@fit$sigma, m_),
                       prereturns = tail(sp500ret, m_),
                       #Preresiduals ARE NOT standardized:
                       preresiduals = tail(garch_resid, m_),
                       startMethod = "sample",
                       #Distfit in custom.dist ARE standardized
                       custom.dist = custom_dist)
#Extract simulated series
sp_sim <- garch_sim@simulation$seriesSim
#Test
sp_df <- cbind(sp500ret, sim = sp_sim) %>% 
  setNames(c("ret", "sim")) %>% 
  as_tibble(rownames = "date") %>% 
  mutate(date = as.Date(date),
         diff = sim - ret)
egarch<-function(n_sim) {
  garch_sim <- ugarchsim(fit, 
                         n.sim = n_sim,
                         m.sim = 1, 
                         presigma = tail(fit@fit$sigma, m_),
                         prereturns = tail(sp500ret, m_),
                         #Preresiduals ARE NOT standardized:
                         preresiduals = tail(garch_resid, m_),
                         startMethod = "sample",
                         #Distfit in custom.dist ARE standardized
                         #Custom.dist = custom_dist
                         )
  values = as.numeric(garch_sim@simulation$seriesSim)
  return(values)
}
```

Three different bubble patterns are being considered.

```{r, warning=FALSE}
#Bubble's collapse pattern.
bubble <- function(n, te = 0.4 * n, tf = te + 0.2 * n , tr = tf + 0.1*n,
                   c = 1, c1 = 1, c2 = 1, eta = 0.6, alpha = 0.6, beta = 0.5) {
  drift <- c*n^(-eta)
  delta <- 1 + c1 * n^(-alpha)
  gamma <- 1 - c2 * n^(-beta)
  y <- 100
  err <- egarch(n)*1.5
  for (t in 2:n) {
    if (t < te) {
      y[t] <- drift + y[t - 1] + err[t]
    } else if (t >= te & t <= tf) {
      y[t] <- delta * y[t - 1] + err[t]
    } else if (t > tf & t <= tr ) {
      y[t] <- gamma * y[t - 1] + err[t]
    } else {
      y[t] <- drift + y[t - 1] + err[t]
    }
  }
  y %>%
    add_class("sim") 
}
#Duoble collapse (not used)
bubble_2 <- function(n,
                    te1 = 0.3 * n, tf1 = te1 + 0.1 * n , tr1 = tf1 + 0.1*n,
                    te2 = 0.8 * n, tf2 = te2 + 0.1 * n , tr2 = tf2 + 0.1*n,
                    c = 1, c1 = 1, c2 = 1, eta = 0.6, alpha = 0.6, beta = 0.7) {
  
  drift <- c*n^(-eta)
  delta <- 1 + c1 * n^(-alpha)
  gamma <- 1 - c2 * n^(-beta)
  y <- 100
  err <- egarch(n)
  for (t in 2:n) {
    if (t < te1) {
      y[t] <- drift + y[t - 1] + err[t] #Normal
    } else if (t >= te1 & t <= tf1) {
      y[t] <- delta * y[t - 1] + err[t] #Bubble1
    } else if (t > tf1 & t <= tr1 ) {
      y[t] <- gamma * y[t - 1] + err[t] #Collapse 1
    }  else if (t > tr1 + 1 & t < te2) {
      y[t] <- drift + y[t - 1] + err[t] #Normal 2
    }  else if (t >= te2 + 1 & t <= tf2) {
      y[t] <- delta * y[t - 1] + err[t] #Bubble 2
    }  else if (t > tf2 + 1 & t <= tr2) {
      y[t] <- gamma * y[t - 1] + err[t] #Collapse 2
    } else {
      y[t] <- drift + y[t - 1] + err[t] #Normal 3
    }
  }
  y %>%
    add_class("sim")
}
#Final patterns
set.seed(000)
time = 100
disturbing <- bubble(time, te = time*0.4, tf= time*0.6, tr = time*0.7, beta = 0.5, alpha = 0.6)
sudden <- bubble(time, time*0.5, tf= time*0.6, tr = time*0.66, beta = 0.3, alpha = 0.6, eta = 0.03)
smooth <- bubble(time, time*0.4, tf= time*0.6, tr = time*0.8, beta = 0.9, alpha = 0.6,eta=0.2)
```

The following chunk outlines a graphical representation of potential patterns of bubble collapse.

```{r, warning=FALSE}
autoplot(disturbing)
autoplot(smooth)
autoplot(sudden)
```

The BSADF (state-of-the-art statistical model) is compared with the Kolmogorov-Smirnov Change Point Detection Model (KS-CPM). The disruptive path is initially examined, followed by 1000 simulations.

```{r, warning=FALSE}
#Distirubing(40,60,70)
matrix_empty = matrix(nrow = 100, ncol = 1000)
set.seed(002)
cyc = c(1:1000)
DIS <- data.frame(matrix_empty)
for (i in cyc){
  DIS[,i] <- bubble(time, te = time*0.4, tf= time*0.6, tr = time*0.7, beta = 0.5, alpha = 0.6)
}
results_DIS <- list()
ADF_DIS <- list()
for (i in cyc){
  tryCatch({ss <- diff(log(DIS[,i]))
  test <- processStream(ss,"Kolmogorov-Smirnov",ARL0=500, startup=17) #startuo 17%, ARL0=500
  results_DIS[[i]]<-test$changePoint
  remove(test)
  radf_sim <- radf(ts(DIS[,i]))
  d<-datestamp(radf_sim)
  ADF_DIS[[i]] <- c(d$series1$Start,d$series1$Peak,d$series1$End)
  remove(d)
  remove(radf_sim)
  print(i)
},error=function(e){cat('ERROR:',conditionMessage(e),'\n')})}
results_DIS
ADF_DIS
correct<-length(results_DIS[lengths(results_DIS) == 3])
correct_ADF<-length(ADF_DIS[lengths(ADF_DIS) == 3])
#914
#843
```

Below, the simulation results are summarized, taking into account both the frequency of correct bubble identifications and the Root Mean Square Error (RMSE).

```{r, warning=FALSE}
#Correctness KS-CPM
matrix_test = matrix(ncol = 3, nrow = correct)
matrix_ADF = matrix(ncol = 3, nrow = correct_ADF)
for(i in 1:correct){
matrix_test[i,]<-c(results_DIS[lengths(results_DIS) == 3][[i]][1],results_DIS[lengths(results_DIS) == 3] [[i]][2],results_DIS[lengths(results_DIS) == 3][[i]][3])
}
dim(matrix_test)[1]
#Correctness BSADF test
for(i in 1:correct_ADF){
matrix_ADF[i,]<-c(as.numeric(substr(ADF_DIS[lengths(ADF_DIS) == 3][[i]][1], 2, 4)),as.numeric(substr(ADF_DIS[lengths(ADF_DIS) == 3][[i]][2], 2, 4)),as.numeric(substr(ADF_DIS[lengths(ADF_DIS) == 3][[i]][3], 2, 4)))
}
dim(matrix_ADF)[1]
#RMSE KS-CPM
Metrics::rmse(matrix_test[,1],rep(40,correct))
Metrics::rmse(matrix_test[,2],rep(60,correct))
Metrics::rmse(matrix_test[,3],rep(70,correct))
Metrics::rmse(c(matrix_test[,1],matrix_test[,2],matrix_test[,3]),c(rep(40,correct),rep(60,correct),rep(70,correct)))
#RMSE BSADF test
Metrics::rmse(matrix_ADF[,1],rep(40,correct_ADF))
Metrics::rmse(matrix_ADF[,2],rep(60,correct_ADF))
Metrics::rmse(matrix_ADF[,3],rep(70,correct_ADF))
Metrics::rmse(c(matrix_ADF[,1],matrix_ADF[,2],matrix_ADF[,3]),c(rep(40,correct_ADF),rep(60,correct_ADF),rep(70,correct_ADF)))
```

The same analysis is conducted for the abrupt path.

```{r, warning=FALSE}
#Sudden(50,60,66)
matrix_empty = matrix(nrow = 100, ncol = 1000)
set.seed(003)
SUD <- data.frame(matrix_empty)
for (i in cyc){
  SUD[,i] <- bubble(time, time*0.5, tf= time*0.6, tr = time*0.66, beta = 0.3, alpha = 0.6, eta = 0.03)
}
results_SUD <- list()
ADF_SUD <- list()
for (i in cyc){
  tryCatch({ss <- diff(log(SUD[,i]))
  test <- processStream(ss,"Kolmogorov-Smirnov",ARL0=500, startup=17) #startuo 17%, ARL0=500
  results_SUD[[i]]<-test$changePoints
  remove(test)
  radf_sim <- radf(ts(SUD[,i]))
  d<-datestamp(radf_sim)
  ADF_SUD[[i]] <- c(d$series1$Start,d$series1$Peak,d$series1$End)
  remove(d)
  remove(radf_sim)
  print(i)
  },error=function(e){cat('ERROR:',conditionMessage(e),'\n')})}
results_SUD
correct<-length(results_SUD[lengths(results_SUD) == 3])
correct_ADF<-length(ADF_SUD[lengths(ADF_SUD) == 3])
ADF_SUD
#846
#545
```

```{r, warning=FALSE}
#Correctness KS-CPM
matrix_test = matrix(ncol = 3, nrow = correct)
matrix_ADF = matrix(ncol = 3, nrow = correct_ADF)
for(i in 1:correct){
matrix_test[i,]<-c(results_SUD[lengths(results_SUD) == 3][[i]][1],results_SUD[lengths(results_SUD) == 3] [[i]][2],results_SUD[lengths(results_SUD) == 3] [[i]][3])
}
dim(matrix_test)[1]
#Correctness BSADF test
for(i in 1:correct_ADF){
matrix_ADF[i,]<-c(as.numeric(substr(ADF_SUD[lengths(ADF_SUD) == 3][[i]][1], 2, 4)),as.numeric(substr(ADF_SUD[lengths(ADF_SUD) == 3][[i]][2], 2, 4)),as.numeric(substr(ADF_SUD[lengths(ADF_SUD) == 3][[i]][3], 2, 4)))
}
dim(matrix_ADF)[1]
#RMSE KS-CPM
Metrics::rmse(matrix_test[,1],rep(50,correct))
Metrics::rmse(matrix_test[,2],rep(60,correct))
Metrics::rmse(matrix_test[,3],rep(66,correct))
Metrics::rmse(c(matrix_test[,1],matrix_test[,2],matrix_test[,3]),c(rep(50,correct),rep(60,correct),rep(66,correct)))
#RMSE BSADF test
Metrics::rmse(matrix_ADF[,1],rep(50,correct_ADF))
Metrics::rmse(matrix_ADF[,2],rep(60,correct_ADF))
Metrics::rmse(matrix_ADF[,3],rep(66,correct_ADF))
Metrics::rmse(c(matrix_ADF[,1],matrix_ADF[,2],matrix_ADF[,3]),c(rep(50,correct_ADF),rep(60,correct_ADF),rep(66,correct_ADF)))
```

Finally, the analysis is extended to include the smoothing path as well.

```{r, warning=FALSE}
#Smooth(40,60,80)
matrix_empty = matrix(nrow = 100, ncol = 1000)
set.seed(004)
SMO <- data.frame(matrix_empty)
for (i in cyc){
  SMO[,i] <- bubble(time, time*0.4, tf= time*0.6, tr = time*0.8, beta = 0.9, alpha = 0.6,eta=0.2)
}
results_SMO <- list()
ADF_SMO <- list()
for (i in cyc){
  tryCatch({ss <- diff(log(SMO[,i]))
  test <- processStream(ss,"Kolmogorov-Smirnov",ARL0=500, startup=17) #startuo 17%, ARL0=500
  results_SMO[[i]]<-test$changePoints
  remove(test)
  radf_sim <- radf(ts(SMO[,i]))
  d<-datestamp(radf_sim)
  ADF_SMO[[i]] <- c(d$series1$Start,d$series1$Peak,d$series1$End)
  remove(d)
  remove(radf_sim)
  print(i)
},error=function(e){cat('ERROR:',conditionMessage(e),'\n')})}
results_SMO
correct<-length(results_SMO[lengths(results_SMO) == 3])
correct_ADF<-length(ADF_SMO[lengths(ADF_SMO) == 3])
ADF_SMO
#885
#804
```

```{r, warning=FALSE}
#Correctness KS-CPM
matrix_test = matrix(ncol = 3, nrow = correct)
matrix_ADF = matrix(ncol = 3, nrow = correct_ADF)
for(i in 1:correct){
matrix_test[i,]<-c(results_SMO[lengths(results_SMO) == 3][[i]][1],results_SMO[lengths(results_SMO) == 3] [[i]][2],results_SMO[lengths(results_SMO) == 3] [[i]][3])
}
dim(matrix_test)[1]
#Correctness BSADF test
for(i in 1:correct_ADF){
matrix_ADF[i,]<-c(as.numeric(substr(ADF_SMO[lengths(ADF_SMO) == 3][[i]][1], 2, 4)),as.numeric(substr(ADF_SMO[lengths(ADF_SMO) == 3][[i]][2], 2, 4)),as.numeric(substr(ADF_SMO[lengths(ADF_SMO) == 3][[i]][3], 2, 4)))
}
dim(matrix_ADF)[1]
#RMSE KS-CPM
Metrics::rmse(matrix_test[,1],rep(40,correct))
Metrics::rmse(matrix_test[,2],rep(60,correct))
Metrics::rmse(matrix_test[,3],rep(80,correct))
Metrics::rmse(c(matrix_test[,1],matrix_test[,2],matrix_test[,3]),c(rep(40,correct),rep(60,correct),rep(80,correct)))
#RMSE BSADF test
Metrics::rmse(matrix_ADF[,1],rep(40,correct_ADF))
Metrics::rmse(matrix_ADF[,2],rep(60,correct_ADF))
Metrics::rmse(matrix_ADF[,3],rep(80,correct_ADF))
Metrics::rmse(c(matrix_ADF[,1],matrix_ADF[,2],matrix_ADF[,3]),c(rep(40,correct_ADF),rep(60,correct_ADF),rep(80,correct_ADF)))
```


The simulation study indicates evidence of the change point detection model outperforming the BSADF test. Attention can now be shifted to real data analysis.

#Empirical analysis, Renixx index

To transition to the real data example, the Rennix index is selected for empirical analysis.

```{r, warning=FALSE}
#Updating of the data.
renixx <- read.csv("Economic variables/Rennix_index.csv")
#Descriptive statistics
renixx$date<-ymd(renixx$date)
renixx<-renixx[order(renixx$date),]
rownames(renixx)<-NULL
renixx<-renixx[256:dim(renixx)[1],]
ggplot(renixx, aes(date, close))+geom_line()+ggtitle('Renixx index')+xlab('Time')+ylab('Absolute Returns')
#Log-returns
renixx$date<-ymd(renixx$date)
df <- renixx %>% dplyr::select(1,3)
rownames(df) <- NULL
df$abs <- abs(c(0,diff(log(df$close))))
#Absolute log-returns
df$rate <- c(0,diff(log(df$close)))
ggplot(df, aes(date, abs))+geom_line()
```

```{r, warning=FALSE}
#KS-CPM
test <- processStream(ts(df$rate,freq=52,start=decimal_date(ymd("2005-1-1"))),"Kolmogorov-Smirnov", ARL0=5000, startup=round(dim(df)[1]*17/100)) #17% initial sample, ARL0 5000 as proposed
breack<-df$date[test$changePoints]
allarm<-df$date[test$detectionTimes]
plot(df$date, df$close, type = "l", xlab = "Observation", ylab = "", bty = "l",main='Renixx')
abline(v = breack, lty = 2, col = 'red')
#Results
test
```

The following chunk outlines the results for the daily time series using the KS-CPM.

```{r, warning=FALSE}
breack
df$Date <- as.POSIXct(df$date, format = "%Y-%m-%d")
g<-ggplot(df, aes(x = Date, y=(close))) +
  geom_line(aes(color="RENIXX")) +
  theme_light()+ylab('Value')+xlab('Time')+ggtitle('Daily Data')+theme(plot.title = element_text(hjust = 0.9))+
   annotate("text", x = df$Date[730], y = df$close[730]+100, label = "Bubble Burst")+
  geom_segment(aes(x = df$Date[730], y = 0, xend = df$Date[730], yend =df$close[730]),linetype="dashed", color = "red")+
     annotate("text", x = df$Date[1364], y = df$close[1164]+100, label = "Bubble Decline")+
  geom_segment(aes(x = df$Date[1164], y = 0, xend = df$Date[1164], yend =df$close[1164]),linetype="dashed", color = "red")+
  annotate("text", x = df$Date[2016], y = df$close[2016]+250, label = "Bubble End")+
  geom_segment(aes(x = df$Date[2016], y = 0, xend = df$Date[2016], yend =df$close[2016]),linetype="dashed", color = "orange")+
  annotate("text", x = df$Date[2883], y = df$close[2883]+150, label = "Restore")+
  geom_segment(aes(x = df$Date[2883], y = 0, xend = df$Date[2883], yend =df$close[2883]),linetype="dashed", color = "green")+
      annotate("text", x = df$Date[4123], y = df$close[3823]-160, label = "Bubble Start")+
  geom_segment(aes(x = df$Date[3823], y = 0, xend = df$Date[3823], yend =df$close[3823]),linetype="dashed", color = "orange")+
annotate("rect", xmin = as.POSIXct(c(df$Date[1164],df$Date[2883])), xmax = as.POSIXct(c(df$Date[2016],df$Date[3823])), ymin = 0, ymax = Inf, alpha = .2,fill="orange")+
  annotate("rect", xmin = as.POSIXct(c(df$Date[1],df$Date[730],df$Date[3823])), xmax = as.POSIXct(c(df$Date[730],df$Date[1164],df$Date[dim(df)[1]])), ymin = 0, ymax = Inf, alpha = .2,fill="red")+
    annotate("rect", xmin = as.POSIXct(df$Date[2016]), xmax = as.POSIXct(df$Date[2883]), ymin = 0, ymax = Inf, alpha = .2,fill="green")+
  geom_point(data=df[c(730,1164),], aes(x = Date, y=(close)), colour="red", size=2)+
  geom_point(data=df[c(2016,3823),], aes(x = Date, y=(close)), colour="orange", size=2)+
  geom_point(data=df[c(2883),], aes(x = Date, y=(close)), colour="green", size=2)+
  scale_color_manual(name='Series',
                     breaks=c('RENIXX'),
                     values=c('RENIXX'='darkgreen'))
g
```

The same analysis is conducted for the monthly frequency.

```{r, warning=FALSE}
Month<- as.Date(cut(df$date, "month"))
renixx_m <- aggregate(close ~ Month, df, mean)
#Log-returns
renixx_m$Renixx <- c(0,diff(log(renixx_m$close)))
#Absolute log-returns
renixx_m$abs <- c(0,abs(diff(log(renixx_m$close))))
#Standardized values
renixx_m$St<-log(renixx_m$close)
ggplot(renixx_m, aes(Month, abs))+geom_line()+xlab('Time')+ylab('Absolute Returns')+ggtitle('Renixx index')
ggplot(renixx_m, aes(Month, close))+geom_line()+xlab('Time')+ylab('Value')+ggtitle('Renixx index')
```

```{r, warning=FALSE}
#KS-CPM
test <- processStream(ts(renixx_m$Renixx,freq=12,start=decimal_date(ymd("2005-1-1"))),"Kolmogorov-Smirnov", ARL0=500, startup=dim(renixx_m)[1]*17/100) #1 initial sample, ARL0=500
breack<-renixx_m$Month[test$changePoints]
plot(renixx_m$Month, renixx_m$close, type = "l", xlab = "Observation", ylab = "", bty = "l",main='Renixx')
abline(v = breack, lty = 2, col = 'red')
test
```

The previous results are compared with those obtained from the BSADF test.

```{r, warning=FALSE}
set.seed(123)
series <- ts(renixx_m[,c(2,4)],frequency=12,start=c(2005,1))
results<-radf(series[,1])
autoplot(results)+labs(title = "Renixx BSADF")
d_adf<-datestamp(results)
d_adf
```
There is clear evidence that the BSADF is specialized in detecting explosive behaviors, which are a specific aspect of bubble dynamics. This indicates the need for a more comprehensive tool that incorporates the entire lifecycle of a bubble, including its start, burst, and end phases.

#Dataset

To analyze the green bubbles, various variables will be taken into account. Two main groups stand out: economic/financial variables and Google Trends data.

```{r, warning=FALSE}
#Oil WTI Futures
Oil <- read.csv("Economic variables/Crude Oil WTI Futures Historical Data_2005.csv")
Oil$Date <- mdy(Oil$Date)
Month <- as.Date(cut(Oil$Date, "month"))
Oil_m <- aggregate(Price ~ Month, Oil, mean)
#Trasformations
Oil_m$Rate_O<-c(0,diff(log(Oil_m$Price)))
Oil_m$Rate_s<-scale(c(0,diff(Oil_m$Price)),scale=TRUE,center=TRUE)
rownames(Oil_m)<-NULL
ggplot(Oil_m, aes(Month, Price))+geom_line()+ggtitle('Oil price')
```

```{r, warning=FALSE}
#Geopolitical index 
data_gpr_export <- read_excel("Economic variables/data_gpr_daily_recent.xls")
geo_i <- data_gpr_export %>% dplyr::select(6,3)
colnames(geo_i)[1] <- "Date"
geo_i2 <- geo_i[geo_i$Date <= "2022-12-30" & geo_i$Date >= "2005-01-01", ]
Month <- as.Date(cut(geo_i2$Date, "month"))
geo_m <- aggregate(geo_i2$GPRD ~ Month,geo_i2, mean)
colnames(geo_m)[2] <- "GPRH"
geo_m$GPRH<-as.numeric(geo_m$GPRH)
#Trasformations
geo_m$Rate_g <- c(0,diff(log(geo_m$GPRH)))
geo_m$St <- scale(c(0,diff(geo_m$GPRH)),scale=TRUE,center=TRUE)
ggplot(geo_m, aes(Month, GPRH))+geom_line()+ggtitle('Geopolitical index')
```

```{r, warning=FALSE}
#MSCI_WORLD
MSCI<-read_csv("Economic variables/MSCI World_2005.csv")
MSCI_2 <- MSCI %>% dplyr::select(6,2)
MSCI_2$Date <- format(as.Date(MSCI_2$Date,format='%m/%d/%y'), "%m/%d/%Y")
MSCI_2$Date <- mdy(MSCI_2$Date)
Month <- as.Date(cut(MSCI_2$Date, "month"))
MSCI_2$Close<-as.numeric(MSCI_2$Close)
MSCI_m <- aggregate(Close ~ Month, MSCI_2, mean)
colnames(MSCI_m)[2] <- "Price"
MSCI_m$Price<-as.numeric(MSCI_m$Price)
#Trasformations
MSCI_m$Rate_ms <- c(0,diff(log(MSCI_m$Price)))
MSCI_m$Rate_s <- scale(c(0,diff(MSCI_m$Price)),scale=TRUE,center=TRUE)
ggplot(MSCI_m, aes(Month, Price))+geom_line()+ggtitle('Global MSCI index')
```

The following section illustrates the two bubbles present in the renewable energy market. Additionally, the correlation among these three series will be demonstrated by outlining the oil and MSCI ratio.

```{r, warning=FALSE}
#Ratio
renixx_m$Oil_ratio<-renixx_m$close/Oil_m$Price
renixx_m$MSCI_ratio<-renixx_m$close/MSCI_m$Price
#Final plot for green bubble detection
renixx_m$Date <- as.POSIXct(renixx_m$Month, format = "%Y-%m-%d")
df_rect<-data.frame(xmin = c(as.POSIXct(d_adf$series1$Start)), xmax = c(as.POSIXct(d_adf$series1$End)), ymin = 0, ymax = Inf,Explosive=c("BSADF"))
g<-ggplot(renixx_m, aes(x = Date, y=(close/30))) +
  geom_line(aes(color="RENIXX")) +
  geom_line(aes(y = MSCI_ratio*10, color = "Oil ratio"), linetype="twodash") + 
  geom_line(aes(y = Oil_ratio/2, color="MSCI ratio"), linetype="twodash") +
  theme_light()+ylab('Value')+xlab('Time')+ggtitle('Empirical Analysis')+theme(plot.title = element_text(hjust = 0.5))+
  geom_segment(aes(x = renixx_m$Date[36], y = 0, xend = renixx_m$Date[36], yend =renixx_m$close[36]/30),linetype="dashed", color = "red")+
   annotate("text", x = renixx_m$Date[36], y = renixx_m$close[36]/30+5, label = "Bubble Burst")+
    geom_segment(aes(x = renixx_m$Date[95], y = 0, xend = renixx_m$Date[95], yend =renixx_m$close[95]/30),linetype="dashed", color = "red")+
  annotate("text", x = renixx_m$Date[95], y = renixx_m$close[95]/30+5, label = "Bubble End")+
      geom_segment(aes(x = renixx_m$Date[124], y = 0, xend = renixx_m$Date[124], yend =renixx_m$close[124]/30),linetype="dashed", color = "red")+
  annotate("text", x = renixx_m$Date[125], y = renixx_m$close[124]/30+5, label = "Restore")+
    geom_segment(aes(x = renixx_m$Date[178], y = 0, xend = renixx_m$Date[178], yend =renixx_m$close[178]/30),linetype="dashed", color = "red")+
  annotate("text", x = renixx_m$Date[170], y = renixx_m$close[178]/30+5, label = "Bubble Start")+
  geom_rect(data=df_rect,aes(xmin=xmin,ymin=ymin,xmax=xmax,ymax=ymax,fill=Explosive),
                    alpha=0.2,inherit.aes=FALSE)+
  scale_fill_manual(name='Test',values=c("azure4"))+
  geom_point(data=renixx_m[c(36,95,124,178), ], aes(x = Date, y=(close/30)), colour="red", size=2)+
  scale_color_manual(name='Time Series',
                     breaks=c('RENIXX', 'Oil ratio', 'MSCI ratio'),
                     values=c('RENIXX'='darkgreen', 'Oil ratio'='darkred', 'MSCI ratio'='steelblue'))

grid.arrange(g)
```

Below, the other variables are outlined.

```{r, warning=FALSE}
#Policy risk and Financial risk
GEPUCURRENT <- read.csv("Economic variables/GEPUCURRENT.csv")
GEPUCURRENT$DATE<-ymd(GEPUCURRENT$DATE)
GEPUCURRENT<-GEPUCURRENT[97:312,]
rownames(GEPUCURRENT) <- NULL
GEPUCURRENT$Rate<-c(0,diff(log(GEPUCURRENT$GEPUCURRENT)))
GEPUCURRENT$Rate_s<-scale(c(0,diff(GEPUCURRENT$GEPUCURRENT)),scale=TRUE,center=TRUE)
#Trasformation
Fs<-read.csv("Economic variables/Fs.csv")
Month<- as.Date(cut(ymd(Fs$Date), "month"))
Fs_m <- aggregate(OFR.FSI ~ Month, Fs, mean)
Fs_m<-Fs_m[61:276,]
Fs_m$Rate<-c(0,diff(Fs_m$OFR.FSI))
Fs_m$Rate_s<-scale(c(0,diff(Fs_m$OFR.FSI)),scale=TRUE,center=TRUE) #(presence of 0s, no log transformation)
ggplot(Fs_m, aes(Month, OFR.FSI))+geom_line()+ggtitle('Financial Stability')
ggplot(GEPUCURRENT, aes(DATE, GEPUCURRENT))+geom_line()+ggtitle('Policy Uncertainty')
```

```{r, warning=FALSE}
#Financial/economic variables
Finance<-renixx_m[,c(1,3)]
colnames(Finance)[2] <- "Renixx"
Finance$Oil_p<-Oil_m$Rate_O
Finance$MSCI<-MSCI_m$Rate_ms
Finance$EPU<-GEPUCURRENT$Rate
Finance$OFR<-Fs_m$Rate
Finance$Geo_i<-geo_m$Rate_g
#Economic dataset
Finance_2<-renixx_m[,c(1,2)]
colnames(Finance_2)[2] <- "Renixx"
Finance_2$Renixx<-scale(Finance_2$Renixx,center=TRUE,scale=TRUE)
Finance_2$Oil_p<-scale(Oil_m$Price,center=TRUE,scale=TRUE)
Finance_2$Geo_i<-scale(geo_m$GPRH,center=TRUE,scale=TRUE)
Finance_2$MSCI<-scale(MSCI_m$Price,center=TRUE,scale=TRUE)
Finance_2$EPU<-scale(GEPUCURRENT$GEPUCURRENT,center=TRUE,scale=TRUE)
Finance_2$OFR<-scale(Fs_m$OFR.FSI,center=TRUE,scale=TRUE)
#Plot
ggplot() + 
  geom_line(data = Finance_2, aes(x = Month, y = Renixx, color = "Rennix")) +
  geom_line(data = Finance_2, aes(x = Month, y = MSCI, color = "Global MSCI")) +
  geom_line(data = Finance_2, aes(x = Month, y = Geo_i, color = "Geopolitical index")) +
  geom_line(data = Finance_2, aes(x = Month, y = Oil_p, color = "Oil price")) +
  geom_line(data = Finance_2, aes(x = Month, y = EPU, color = "EPU")) +
  geom_line(data = Finance_2, aes(x = Month, y = OFR, color = "OFR")) +
  xlab('data_date') + ggtitle('Financial time series')+
  ylab('Monthly series')+ scale_color_manual(name='Series',
                     breaks=c('Rennix', 'Global MSCI','Geopolitical index','Oil price','EPU','OFR'),
                     values=c('Rennix'='green', 'Global MSCI'='red','Geopolitical index'='blue','Oil price'='brown','EPU'='orange','OFR'='grey'))
```

Similarly, the analysis extends to the text variables utilized in the study.

```{r, warning=FALSE}
#Text variables
#Green Energy
green_e <- read.csv("Google Trends/Green_energy.csv", header=TRUE, comment.char="#")[13:228,]
green_e$Time<-ymd(green_e$Time)
green_e$Rate<-c(0,diff(log(green_e$Absolute.Google.Search.Volume)))
Climate<-as.data.frame(green_e[,1]) 
colnames(Climate)[1] <- "Date"
Climate$Green_e<-green_e[,4]
#New technology
Tech_d <- read.csv("Google Trends/New Technology.csv", header=TRUE, comment.char="#")[13:228,]
Tech_d$Rate<-c(0,diff(log(Tech_d$Absolute.Google.Search.Volume)))
Climate$Tech<-Tech_d[,4]
#Energy index
Energy_i <- read.csv("Google Trends/Energy_index.csv", header=TRUE, comment.char="#")[13:228,]
Energy_i<-Energy_i[,c(1,2,3)]
Energy_i$Rate<-c(0,diff(log(Energy_i$Absolute.Google.Search.Volume)))
Climate$Energy_i<-Energy_i[,4]
#Global warming
global_w <- read.csv("Google Trends/Global_warming.csv", header=TRUE, comment.char="#")[13:228,]
global_w$Rate<-c(0,diff(log(global_w$Absolute.Google.Search.Volume)))
Climate$Warming<-global_w[,4]
#Natural disaster
Natural <- read.csv("Google Trends/Natural_disasters.csv", header=TRUE, comment.char="#")[13:228,]
Natural$Rate<-c(0,diff(log(Natural$Absolute.Google.Search.Volume)))
Climate$Natural<-Natural[,4]
#Carbon price
Carbon_p <- read.csv("Google Trends/Carbon_price.csv", header=TRUE, comment.char="#")[13:228,]
Carbon_p$Rate<-c(0,diff(log(Carbon_p$Absolute.Google.Search.Volume)))
Climate$Carbon_p<-Carbon_p[,4]
#Carbon tax
Tax <- read.csv("Google Trends/Carbon_tax.csv", header=TRUE, comment.char="#")[13:228,]
Tax$Rate<-c(0,diff(log(Tax$Absolute.Google.Search.Volume)))
Climate$Tax<-Tax[,4]
#Energy shares
Energy_s <- read.csv("Google Trends/Energy_shares.csv", header=TRUE, comment.char="#")[13:228,]
Energy_s$Rate<-c(0,diff(log(Energy_s$Absolute.Google.Search.Volume)))
Climate$Energy_s<-Energy_s[,4]
#Text dataset
Climate_2<-as.data.frame(green_e[,1]) 
colnames(Climate_2)[1] <- "Date"
#Scaling
Climate_2$Green_e<-scale(as.numeric(green_e[,3]),center = TRUE,scale=TRUE)
Climate_2$Tech<-scale(as.numeric(Tech_d[,3]),center = TRUE,scale=TRUE)
Climate_2$Warming<-scale(as.numeric(global_w[,3]),center = TRUE,scale=TRUE)
Climate_2$Energy_i<-scale(as.numeric(Energy_i[,3]),center = TRUE,scale=TRUE)
Climate_2$Natural<-scale(as.numeric(Natural[,3]),center = TRUE,scale=TRUE)
Climate_2$Carbon_p<-scale(as.numeric(Carbon_p[,3]),center = TRUE,scale=TRUE)
Climate_2$Energy_s<-scale(as.numeric(Energy_s[,3]),center = TRUE,scale=TRUE)
Climate_2$Energy_T<-scale(as.numeric(Energy_s[,3]+Energy_i[,3])/2,center = TRUE,scale=TRUE)
Climate_2$Energy_s<-scale(as.numeric(Energy_s[,3]),center = TRUE,scale=TRUE)
Climate_2$Tax<-scale(as.numeric(Tax[,3]),center = TRUE,scale=TRUE)
#Plot
ggplot() + 
  geom_line(data = Climate_2, aes(x = Date, y = Green_e, color = "Green Energy")) +
  geom_line(data = Climate_2, aes(x = Date, y = Energy_i, color = "Energy Index")) +
  geom_line(data = Climate_2, aes(x = Date, y = Warming, color = "Global Warming")) +
  geom_line(data = Climate_2, aes(x = Date, y = Natural, color = "Natural Disasters"))+ 
  geom_line(data = Climate_2, aes(x =Date, y = Carbon_p, color = "Carbon price")) +
 geom_line(data = Climate_2, aes(x =Date, y = Energy_s, color = "Energy shares")) +
  geom_line(data = Climate_2, aes(x =Date, y = Tax, color = "Carbon Tax")) +
  geom_line(data = Climate_2, aes(x =Date, y = Tech, color = "New Technology")) +
  xlab('data_date') + ggtitle('Text-time series')+
  ylab('Monthly series')+ scale_color_manual(name='Series',
                     breaks=c('Green Energy', 'Global Warming','Natural Disasters','Carbon price',"New Technology",'Energy Index','Green Bond','Carbon Emissions','Energy shares','Carbon Tax'),
                     values=c('Green Energy'='green','Global Warming'='red', 'Natural Disasters'='gold','Carbon price'='brown','New Technology'='purple','Energy Index'='blue','Carbon Emissions'='orange','Energy shares'='violet','Carbon Tax'='grey'))
```
Correlation plots are valuable tools for summarizing information in terms of descriptive statistics.

```{r, warning=FALSE}
#Correlation-plot
corrplot(cor(Climate[c(1:216),c(2:8)],method='kendall'), hclust.method='ward.D2',addrect=3,rect.col = 'gold',rect.lwd=4,order='hclust',diag=FALSE, method='square',bg='black',col=c('lightblue','green'),tl.col='black')
corrplot(cor(Finance[c(1:216),(2:length(Finance[1,]))],method='kendall'), hclust.method='ward.D2',addrect=3,rect.col = 'gold',rect.lwd=4,order='hclust',diag=FALSE, method='square',bg='black',col=c('lightblue','green'),tl.col='black')
```
The same approach can be applied to the overall dataset, considering three distinct stages: the Clean-tech bubble, the absence of a bubble stage, and the climate bubble.

```{r, warning=FALSE}
#Final dataset
Finance$Merge<-format(as.Date(Finance$Month), "%Y-%m")
Climate$Merge<-format(as.Date(Climate$Date), "%Y-%m")
Data<-merge(Finance,Climate,by="Merge")
Data<- Data[c(2:216),-c(1,9)]
rownames(Data) <- NULL
#Correlation plot
corrplot(cor(Data[1:95,c(2:length(Data[1,]))],method='kendall'),diag=FALSE, method='square',bg='black',col=c('lightblue','green'),tl.col='black')
corrplot(cor(Data[96:178,c(2:length(Data[1,]))],method='kendall'),diag=FALSE, method='square',bg='black',col=c('lightblue','green'),tl.col='black')
corrplot(cor(Data[179:215,c(2:length(Data[1,]))],method='kendall'),diag=FALSE, method='square',bg='black',col=c('lightblue','green'),tl.col='black')
corrplot(cor(Data[,c(2:length(Data[1,]))],method='kendall'),diag=FALSE, method='square',bg='black',col=c('lightblue','green'),tl.col='black')
#"2016-03-01" "2019-10-01"
```

```{r, warning=FALSE}
Climate_2<-Climate_2[c('Date','Green_e','Tech','Warming','Natural','Carbon_p','Energy_i','Energy_s','Tax')]
Finance_2$Merge<-format(as.Date(Finance_2$Month), "%Y-%m")
Climate_2$Merge<-format(as.Date(Climate_2$Date), "%Y-%m")
#Origianl dataset
Data_or<-merge(Finance_2,Climate_2,by="Merge")
Data_or<- Data_or[,-c(1,9)]
rownames(Data_or) <- NULL
```

Before proceeding with the econometric analysis, both the Augmented Dickey-Fuller (ADF) test and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test are conducted to detect the presence of a unit root.

```{r, warning=FALSE}
#ADF for text data
summary(ur.df(Climate[,"Carbon_p"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[,"Green_e"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[,"Tech"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[,"Warming"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[,"Natural"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[3:216,"Tax"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[,"Energy_s"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Climate[,"Energy_i"], type = "drift",lags = 12, selectlags = "AIC"))
#ADF for economic data
summary(ur.df(Finance[,"Oil_p"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Finance[,"Renixx"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Finance[3:216,"MSCI"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Finance[,"EPU"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Finance[3:216,"OFR"], type = "drift",lags = 12, selectlags = "AIC"))
summary(ur.df(Finance[,"Geo_i"], type = "drift",lags = 12, selectlags = "AIC"))
#KPSS for text data
kpss.test(Climate[,"Carbon_p"])
kpss.test(Climate[,"Tech"])
kpss.test(Climate[,"Natural"])
kpss.test(Climate[,"Green_e"])
kpss.test(Climate[,"Warming"])
kpss.test(Climate[,"Energy_s"])
kpss.test(Climate[,"Tax"])
kpss.test(Climate[,"Energy_i"])
#KPSS for economic data
kpss.test(Finance[,"Oil_p"])
kpss.test(Finance[,"Renixx"])
kpss.test(Finance[,"MSCI"])
kpss.test(Finance[,"Geo_i"])
kpss.test(Finance[,"EPU"])
kpss.test(Finance[,"OFR"])
#Arch test due to no log-transformation 
archtest(Finance[,"OFR"])
```

#Bubbles dynamics

The following section is dedicated to analyzing the dynamics of bubbles in the Renixx index. For this analysis, new libraries are required.

```{r, warning=FALSE}
library(bestNormalize)
library(caret)
library(Rssa)
library(lattice)
library(fANCOVA)
library(stats)
library(HoRM)
library(WaveletComp)
library(parameters)
library(TSA)
library(fGarch)
library(fpp)
library(vars)
library(BVAR)
library(Metrics)
library(aTSA)
library(tsoutliers)
library(tsDyn)
library(goft)
library(bruceR)
library(plotmo)
library(grid)
library(factoextra)
library(ggfortify)
library(tvReg)
library(forecast)
```

The plot below illustrates the distribution of text variables based on the three different stages identified by the KS-CPM.

```{r, warning=FALSE}
#Codification
breack
breack_2
breack_3
Data_2<-renixx_m[c(2:216),c('Month','close')]
colnames(Data_2)[2] <- "Renixx"
#Dummy codification
Data_2$dummy_Renixx  <- cut(Data_2$Month,
              breaks= as.Date(c("2005-01-01","2012-12-01","2019-10-01",'2023-01-01')),
              labels=c('Clean-Tech', 'No-bubble', 'Climate'))
#Dataset (economic variables only)
Data_2$dummy_Renixx<-relevel(Data_2$dummy_Renixx, ref = 'No-bubble')
Data_2$Energy_ilag<-lag(Data_or$Energy_i)[2:216]
Data_2$Warminglag<-lag(Data_or$Warming)[2:216]
Data_2$Naturallag<-lag(Data_or$Natural)[2:216]
Data_2$Green_elag<-lag(Data_or$Green_e)[2:216]
Data_2$Carbon_plag<-lag(Data_or$Carbon_p)[2:216]
Data_2$Techlag<-lag(Data_or$Tech)[2:216]
Data_2$Energy_slag<-lag(Data_or$Energy_s)[2:216]
Data_2$Taxlag<-lag(Data_or$Tax)[2:216]
Data_2<-Data_2[,-c(1,2)]
rownames(Data_2) <- NULL
#Info
str(Data_2)
```

```{r, warning=FALSE}
#Density plot for the bubble's stages
p1 <- ggplot(Data_2, aes(x=Green_elag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx))+ labs(fill='Bubble')+
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Green Energy') + ylab('Density')
p2 <- ggplot(Data_2, aes(x=Naturallag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4)+
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Natural Disasters')+ labs(fill='Bubble') + ylab('Density')
p3 <- ggplot(Data_2, aes(x=Carbon_plag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) + xlab('Carbon Price')+
      guides(color = "none")+ geom_density(alpha=0.4) + labs(fill='Bubble') + ylab('Density')
p4 <- ggplot(Data_2, aes(x=Energy_ilag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Energy Index')+ labs(fill='Bubble') + ylab('Density')
p5 <- ggplot(Data_2, aes(x=Warminglag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Global Warming')+ labs(fill='Bubble')+ ylab('Density')
p6 <- ggplot(Data_2, aes(x=Techlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('New Technology')+ labs(fill='Bubble')+ ylab('Density')
p7 <- ggplot(Data_2, aes(x=Energy_slag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('Energy Shares')+ labs(fill='Bubble')+ ylab('Density')
p8 <- ggplot(Data_2, aes(x=Taxlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('Carbon Tax')+ labs(fill='Bubble')+ ylab('Density')
grid.arrange(p1, p2, p3, p4, p5, p6,p7,p8, ncol=4,top = textGrob("RENIXX Index",gp=gpar(fontsize=20,font=3)))
```
Here, we utilize both the logit model and the elastic net regularization technique to forecast explosive behaviors within the time series. Economic and text variables, with their first lag values, are used as potential predictors in the analysis.

```{r, warning=FALSE}
#Dummy codification
Data_2$dummy_Renixx<- as.factor(ifelse(Data$Month >= "2007-07-01" & Data$Month <= "2007-08-01"|Data$Month >= "2007-10-01" & Data$Month <= "2008-01-01"|Data$Month >= "2015-04-01" & Data$Month <= "2015-06-01"|Data$Month >= "2019-12-01" & Data$Month <= "2020-03-01"|Data$Month >= "2020-07-01" & Data$Month <= "2021-05-01"|Data$Month >= "2021-11-01" & Data$Month <= "2021-12-01", 'Explosive','No-Explosive'))
#Dataset
Data_2$dummy_Renixx
Data_2$dummy_Renixx<-relevel(Data_2$dummy_Renixx, ref = 'No-Explosive')
#Economic variables
Data_2$diff_Enii<-lag(scale((renixx_m$close),center=TRUE,scale=TRUE))[2:216]
Data_2$MSCIlag<-lag(MSCI_m$Price)[2:216]
Data_2$Oillag<-lag(Oil_m$Price)[2:216]
Data_2$EPUlag<-lag(GEPUCURRENT$GEPUCURRENT)[2:216]
Data_2$OFRlag<-lag(Fs_m$OFR.FSI)[2:216]
Data_2$GEOlag<-lag(geo_m$GPRH)[2:216]
#Scaling
Data_2$Oillag<-scale(c(0,diff(Data_2$Oillag)),center = TRUE,scale=TRUE)
Data_2$EPUlag<-scale(c(0,diff(Data_2$EPUlag)),center = TRUE,scale=TRUE)
Data_2$MSCIlag<-scale(c(0,diff(Data_2$MSCIlag)),center = TRUE,scale=TRUE)
Data_2$OFRlag<-scale(c(0,diff(Data_2$OFRlag)),center = TRUE,scale=TRUE)
Data_2$GEOlag<-scale(c(0,diff(Data_2$GEOlag)),center = TRUE,scale=TRUE)
```
Density plots for explosive behaviors are also provided.

```{r, warning=FALSE}
#Text variables
p1 <- ggplot(Data_2, aes(x=Green_elag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx))+ labs(fill='Green bubble')+
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Green Energy')
p2 <- ggplot(Data_2, aes(x=Naturallag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4)+
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Natural disaster')+ labs(fill='Green bubble') 
p3 <- ggplot(Data_2, aes(x=Carbon_plag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) + xlab('Carbon price')+
      guides(color = "none")+ geom_density(alpha=0.4) + labs(fill='Green bubble') 
p4 <- ggplot(Data_2, aes(x=Energy_ilag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Energy Index')+ labs(fill='Green bubble') 
p5 <- ggplot(Data_2, aes(x=Warminglag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('Global Warming')+ labs(fill='Green bubble')
p6 <- ggplot(Data_2, aes(x=Techlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('New Technology')+ labs(fill='Green bubble')
p7 <- ggplot(Data_2, aes(x=Energy_slag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('Energy Shares')+ labs(fill='Green bubble')
p8 <- ggplot(Data_2, aes(x=Taxlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('Carbon Tax')+ labs(fill='Green bubble')
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol=2,top = textGrob("Renixx Global Index Explosive Evets",gp=gpar(fontsize=20,font=3)))
```

```{r, warning=FALSE}
#Economic variables
p9 <- ggplot(Data_2, aes(x=OFRlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('OFR')+ labs(fill='Green bubble')
p10 <- ggplot(Data_2, aes(x=MSCIlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
      guides(color = "none")+ geom_density(alpha=0.4) + xlab('MSCI')+ labs(fill='Green bubble')
p11 <- ggplot(Data_2, aes(x=EPUlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('EPU')+ labs(fill='Green bubble')
p12 <- ggplot(Data_2, aes(x=Oillag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('Oil price')+ labs(fill='Green bubble')

p13 <- ggplot(Data_2, aes(x=GEOlag, group=dummy_Renixx, color=dummy_Renixx, fill=dummy_Renixx)) + geom_density(alpha=0.4) +
     guides(color = "none")+ geom_density(alpha=0.4) + xlab('Geo Index')+ labs(fill='Green bubble')

grid.arrange(p9, p10, p11, p12, p13, ncol=2,top = textGrob("Renixx Global Index Explosive Evets",gp=gpar(fontsize=20,font=3)))
```

```{r, warning=FALSE}
#0,1 codification
Data_2$dummy_Renixx<- as.factor(ifelse(Data$Month >= "2007-07-01" & Data$Month <= "2007-08-01"|Data$Month >= "2007-10-01" & Data$Month <= "2008-01-01"|Data$Month >= "2015-04-01" & Data$Month <= "2015-06-01"|Data$Month >= "2019-12-01" & Data$Month <= "2020-03-01"|Data$Month >= "2020-07-01" & Data$Month <= "2021-05-01"|Data$Month >= "2021-11-01" & Data$Month <= "2021-12-01", 1,0))
#Train/validation splitting
train.data  <- Data_2[c(1:190),]
vali.data <- Data_2[c(191:215),]
#Dummy code categorical predictor variables
x <- model.matrix(dummy_Renixx ~., train.data)[,-1]
#Convert the outcome (class) to a numerical variable
y <- train.data$dummy_Renixx
```

```{r, warning=FALSE}
#Elastic net CV
set.seed(123)
seeds <- vector(mode = "list", length = 65)
for(i in 1:64) seeds[[i]] <- sample.int(1000, 15)
seeds[[65]] <- sample.int(1000, 1)
tuneLength.num <- 15
myTimeControl <- trainControl(method = "timeslice",
                              initialWindow = 135,
                              horizon = 20,
                              fixedWindow = FALSE,
                              allowParallel = FALSE,
                              seeds = seeds)

glmnet.mod <- train(dummy_Renixx ~.,
                    data = train.data,
                    method = "glmnet",
                    family = "binomial",
                    trControl = c(myTimeControl),
                    tuneLength=tuneLength.num) 
glmnet.mod
```

```{r, warning=FALSE}
#Fit the final model on the training data
model <- glmnet(x, y, alpha = glmnet.mod$bestTune$alpha, family = "binomial",
                lambda =glmnet.mod$bestTune$lambda)
model_plot <- glmnet(x, y, alpha = glmnet.mod$bestTune$alpha, family = "binomial")
#Display regression coefficients
coef(model)
#Make predictions on the test data
x.test <- model.matrix(dummy_Renixx ~., vali.data)[,-1]
probabilities <- model %>% predict(newx = x.test)
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
#Model accuracy
observed.classes <- vali.data$dummy_Renixx
mean(predicted.classes == observed.classes)
confusionMatrix(as.factor(predicted.classes[,1]), observed.classes)
#Plot of the coefficients
plot(model_plot, xvar = "lambda", label=T)
lbs_fun <- function(fit, offset_x=1, ...) {
L <- length(fit$lambda)
x <- log(fit$lambda[L])+ offset_x
y <- fit$beta[, L]
labs <- names(y)
text(x, y, labels=labs, ...)
}
```

```{r, warning=FALSE}
model_f<-glm(dummy_Renixx ~., family = binomial(link = "logit"), data = Data_2[1:190,c(1:15)])
model_0<-glm(dummy_Renixx ~1, family = binomial(link = "logit"), data = Data_2[1:190,])
model_2<-glm(dummy_Renixx ~MSCIlag+diff_Enii+Energy_ilag+Techlag, family = binomial(link = "logit"), data = Data_2[1:190,])
summary(model_2)
model_2$deviance
-2*logLik(model_2)

vif(model_2)
lrtest (model_0, model_2)
lrtest (model_2, model_f)
blr_linktest(model_2)

list(model = pscl::pR2(model_2)["McFadden"])

model1_data <- augment(model_2) %>% mutate(index = 1:n())

ggplot(model1_data, aes(index, .std.resid, color = dummy_Renixx)) + 
  geom_point(alpha = .5) +
  geom_ref_line(h = 3)

or_glm(data = Data_2[1:190,], model = model_2, incr = c(Naturallag=0.1,Green_elag=0.1,Energy_ilag=0.1,Techlag=0.1,Carbon_plag=0.1,Warminglag=0.1,Energy_slag=0.1,Taxlag=0.1,MSCIlag=0.1,diff_Enii=0.1,Time=0.1,OFRlag=0.1))
```

```{r, warning=FALSE}
predictions <- predict(model_2, type = "response", newdata=Data_2[191:215,])
predictions

threshold <- 0.5
binary_predictions <- ifelse(predictions > threshold, 1, 0)
confusionMatrix(as.factor(binary_predictions), observed.classes)
```
As indicated by the above results, the elastic net regularization model demonstrates superior forecasting performance compared to the logit model.

#Forecasting

The forecasting exercise is conducted for both one-step ahead and multi-step ahead strategies.

```{r, warning=FALSE}
#Descriptive statistcs and tests
Finance$Merge<-format(as.Date(Finance$Month), "%Y-%m")
Climate$Merge<-format(as.Date(Climate$Date), "%Y-%m")
#Dataset for forecsts
Data_3<-merge(Finance,Climate,by="Merge")
Data_3<- Data_3[c(1:216),-c(1,9)]
rownames(Data_3) <- NULL
#Granger causality (12 time frequency of the series)
#MSCI
grangertest(MSCI ~ Renixx, order =12, data = Data_3)
grangertest(MSCI ~ Oil_p, order =12, data = Data_3)#Granger
grangertest(MSCI ~ Geo_i, order =12, data = Data_3)
grangertest(MSCI ~ Energy_i, order =12, data = Data_3)
grangertest(MSCI ~ Green_e, order =12, data = Data_3)
grangertest(MSCI ~ Tech, order =12, data = Data_3)
grangertest(MSCI ~ Warming, order =12, data = Data_3)
grangertest(MSCI ~ Natural, order =12, data = Data_3)
grangertest(MSCI ~ Carbon_p, order =12, data = Data_3)
grangertest(MSCI ~ Tax, order =12, data = Data_3)
grangertest(MSCI ~ Energy_s, order =12, data = Data_3)
grangertest(MSCI ~ EPU, order =12, data = Data_3)
grangertest(MSCI ~ OFR, order =12, data = Data_3)
#Renixx
grangertest(Renixx ~ MSCI, order = 12, data = Data_3)
grangertest(Renixx ~ Oil_p, order = 12, data = Data_3)#Granger
grangertest(Renixx ~ Geo_i, order = 12, data = Data_3)
grangertest(Renixx ~ EPU, order = 12, data = Data_3)#Granger
grangertest(Renixx ~ OFR, order = 12, data = Data_3)
grangertest(Renixx ~ Energy_i, order = 12, data = Data_3)
grangertest(Renixx ~ Green_e, order = 12, data = Data_3)
grangertest(Renixx ~ Tech, order = 12, data = Data_3)
grangertest(Renixx ~ Warming, order = 12, data = Data_3)
grangertest(Renixx ~ Natural, order = 12, data = Data_3)
grangertest(Renixx ~ Carbon_p, order = 12, data = Data_3)
grangertest(Renixx ~ Energy_s, order = 12, data = Data_3)
grangertest(Renixx ~ Tax, order = 12, data = Data_3)#Granger
#Oil price
grangertest(Oil_p ~ MSCI, order = 12, data = Data_3)#Granger
grangertest(Oil_p ~ Natural, order = 12, data = Data_3)
grangertest(Oil_p ~ Geo_i, order = 12, data = Data_3)
grangertest(Oil_p ~ Renixx, order = 12, data = Data_3)
grangertest(Oil_p ~ Green_e, order = 12, data = Data_3)
grangertest(Oil_p ~ Tech, order = 12, data = Data_3)
grangertest(Oil_p ~ Warming, order = 12, data = Data_3)
grangertest(Oil_p ~ Energy_i, order = 12, data = Data_3)
grangertest(Oil_p ~ Carbon_p, order = 12, data = Data_3)
grangertest(Oil_p ~ EPU, order = 12, data = Data_3)
grangertest(Oil_p ~ OFR, order = 12, data = Data_3)#Granger
#OFR
grangertest(OFR ~ MSCI, order = 12, data = Data_3)#Granger
grangertest(OFR ~ Oil_p, order = 12, data = Data_3)#Granger
grangertest(OFR ~ Geo_i, order = 12, data = Data_3)
grangertest(OFR ~ Renixx, order = 12, data = Data_3)#Granger
grangertest(OFR ~ Green_e, order = 12, data = Data_3)
grangertest(OFR ~ Tech, order = 12, data = Data_3)
grangertest(OFR ~ Warming, order = 12, data = Data_3)
grangertest(OFR ~ Natural, order = 12, data = Data_3)
grangertest(OFR ~ Carbon_p, order = 12, data = Data_3)
grangertest(OFR ~ Tax, order = 12, data = Data_3)#Granger
grangertest(OFR ~ EPU, order = 12, data = Data_3)
grangertest(OFR ~ Energy_i, order = 12, data = Data_3)
grangertest(OFR ~ Energy_s, order = 12, data = Data_3)
```

```{r, warning=FALSE}
Data_or$Energy_n<-scale(Energy_i$Absolute.Google.Search.Volume+Energy_s$Absolute.Google.Search.Volume,center=TRUE,scale=TRUE)
ggplot() + 
     geom_line(data = Data_or, aes(x = Month, y = Renixx, color = "Renixx")) +
     geom_line(data = Data_or, aes(x = Month, y = Energy_i, color = 'Energy Index'))+
  geom_line(data = Data_or, aes(x = Month, y = Energy_s, color = 'Energy shares'))+
  xlab('Date') + ggtitle('Renixx vs Google Trends')+
  ylab('Monthly series')+ scale_color_manual(name='Series',
                     breaks=c('Renixx', 'Energy Index', 'Energy shares'),
                     values=c('Renixx'='red', 'Energy Index'='blue','Energy shares'='darkgreen'))

cor(Data_or$Energy_i[121:216],Data_or$Renixx[121:216])
cor(Data_or$Energy_s[121:216],Data_or$Renixx[121:216])
cor(Data_or$Oil_p[121:216],Data_or$Renixx[121:216])
```

Because of the escalating utilization of Google throughout the years, the chosen time frame extends from 2015 to 2022. This decision aims to capture a heightened correlation between text variables and the Renixx index, as depicted in the above plot. In the one-step ahead exercise, four models are taken into account.

*ARIMA

*ARIMAX

*VECM

*NNETAR

```{r, warning=FALSE}
#Dataset for one-step ahead prediction
Data_VECM<-as.data.frame(log(renixx_m$close))
colnames(Data_VECM)[1]<-'Renixx'
#Energy index
Data_VECM$Energy_i<-log(Energy_i$Absolute.Google.Search.Volume)
#Energy share
Data_VECM$Energy_s<-log(Energy_s$Absolute.Google.Search.Volume)
#Oil price
Data_VECM$Oil_p<-log(Oil_m$Price)
```

```{r, warning=FALSE}
#Granger causality
grangertest(Renixx ~ Energy_i, order = 12, data = Data_3[121:216,])#Granger
grangertest(Renixx ~ Energy_s, order = 12, data = Data_3[121:216,])#Granger
grangertest(Renixx ~ Oil_p, order = 12, data = Data_3[121:216,])#Granger
#Vice-versa
grangertest(Energy_s ~ Renixx, order = 12, data = Data_3[121:216,])
grangertest(Energy_i ~ Renixx, order = 12, data = Data_3[121:216,])
grangertest(Oil_p ~ Renixx, order = 12, data = Data_3[121:216,])
#Other variables
grangertest(Renixx ~ MSCI, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Tax, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Oil_p, order = 12, data = Data_3[121:216,])#Granger
grangertest(Renixx ~ Geo_i, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Green_e, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Tech, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Warming, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Natural, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Carbon_p, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ EPU, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ OFR, order = 12, data = Data_3[121:216,])
grangertest(Renixx ~ Energy_i, order = 12, data = Data_3[121:216,])#Granger
grangertest(Renixx ~ Energy_s, order = 12, data = Data_3[121:216,])#Granger
#Climate Minsky moment
grangertest(Energy_s ~ Energy_i, order = 12, data = Data_3[121:216,])
grangertest(Energy_s ~ Oil_p, order = 12, data = Data_3[121:216,])
grangertest(Oil_p ~ Energy_i, order = 12, data = Data_3[121:216,])
grangertest(Oil_p ~ Energy_s, order = 12, data = Data_3[121:216,])
grangertest(Energy_i ~ Energy_s, order = 12, data = Data_3[121:216,])
grangertest(Energy_i ~ Oil_p, order = 12, data = Data_3[121:216,])
grangertest(Oil_p ~ Renixx, order = 12, data = Data_3[121:216,])
grangertest(Oil_p ~ OFR, order = 12, data = Data_3[121:216,])
grangertest(OFR ~ Renixx, order = 12, data = Data_3[121:216,])
grangertest(OFR ~ Oil_p, order = 12, data = Data_3[121:216,])
```

```{r, warning=FALSE}
#Realized values for exogenous variables
Energy_spred <- read.csv("Google Trends/Energy_shares.csv", header=TRUE, comment.char="#")
Energy_ipred <- read.csv("Google Trends/Energy_index.csv", header=TRUE, comment.char="#")
Oil_pred <- read.csv("Predictions/Oil_pred.csv", header=TRUE, comment.char="#")
Oil_pred$Date <- dmy(Oil_pred$Date)
Month <- as.Date(cut(Oil_pred$Date, "month"))
Oil_predm <- aggregate(Price ~ Month, Oil_pred, mean)
Oil_predm<-Oil_predm[217:228,]
Renixx_pred <- read.csv("Predictions/Renixx_pred.csv", header=TRUE, comment.char="#")
Renixx_pred$date <- ymd(Renixx_pred$date)
Month <- as.Date(cut(Renixx_pred$date, "month"))
Renixx_predm <- aggregate(close ~ Month, Renixx_pred, mean)
data_pred0<-data.frame(log(Renixx_predm$close),log(Energy_ipred[229:240,3]),log(Oil_predm$Price),log(Energy_spred[229:240,3]))
colnames(data_pred0)<-c('Renixx','Energy_i','Oil_p',"Energy_s")
#Realized dataset
data_pred<-rbind(Data_VECM[c(121:216),c('Renixx','Energy_i','Oil_p',"Energy_s")],data_pred0)
rownames(data_pred)<-NULL
```

```{r, warning=FALSE}
#Parameter setting
iteration<-12
models<-5
sample<-length(data_pred[,1])
predictions_uni<-as.data.frame(matrix(nrow=iteration,ncol=models))
colnames(predictions_uni)<-c('ARIMA','ARIMAX','ARIMAX2','VAR','NNETAR')
up_uni<-as.data.frame(matrix(nrow=iteration,ncol=models))
colnames(up_uni)<-c('ARIMA','ARIMAX','ARIMAX2','VAR','NNETAR')
lower_uni<-as.data.frame(matrix(nrow=iteration,ncol=models))
colnames(lower_uni)<-c(c('ARIMA','ARIMAX','ARIMAX2','VAR','NNETAR'))
```

```{r, warning=FALSE}
#Arima
all_series<-ts(data_pred,start=c(2015,1),frequency=12)
for(i in 96:(sample-1)){
arima<-auto.arima(all_series[1:i,c('Renixx')],seasonal = TRUE)
pred_arima<-forecast::forecast(arima,h=1)
predictions_uni[(i-96+1),1]<-pred_arima$mean
lower_uni[(i-96+1),1]<-pred_arima$lower[,2]
up_uni[(i-96+1),1]<-pred_arima$upper[,2]
}
```

```{r, warning=FALSE}
#Arimax with oil
data_pred2<-cbind(data_pred$Renixx,lag(data_pred[,2:4]))[2:length(data_pred[,1]),] #lag values to prevent overconfidence
rownames(data_pred2)<-NULL
colnames(data_pred2)<-c('Renixx','Oil_p')
all_series<-ts(data_pred2,start=c(2015,1),frequency=12)
for(i in (96-1):(sample-1-1)){
x<-matrix(all_series[1:i,c('Oil_p')],ncol=1)
colnames(x)<-c('Oil_p')
arimax<-auto.arima(all_series[1:i,1],seasonal = TRUE, xreg=x)
new<-matrix(all_series[(i+1),c('Oil_p')],ncol=1)
colnames(new)<-c('Oil_p')
pred_arimax<-forecast::forecast(arimax,xreg=new)
predictions_uni[(i-(96-1)+1),2]<-pred_arimax$mean
lower_uni[(i-(96-1)+1),2]<-pred_arimax$lower[,2]
up_uni[(i-(96-1)+1),2]<-pred_arimax$upper[,2]
}
```

```{r, warning=FALSE}
#Arimax with text data
data_pred2<-cbind(data_pred$Renixx,lag(data_pred[,2:4]))[2:length(data_pred[,1]),] #lag values to prevent overconfidence
rownames(data_pred2)<-NULL
colnames(data_pred2)<-c('Renixx','Energy_i','Oil_p',"Energy_s")
all_series<-ts(data_pred2,start=c(2015,1),frequency=12)
for(i in (96-1):(sample-1-1)){                        
arimax<-auto.arima(all_series[1:i,1],seasonal = TRUE, xreg=all_series[1:i,c('Energy_i','Energy_s')])
new<-matrix(all_series[(i+1),c('Energy_i','Energy_s')],ncol=2)
colnames(new)<-c('Energy_i','Energy_s')
pred_arimax<-forecast::forecast(arimax,xreg=new)
predictions_uni[(i-(96-1)+1),3]<-pred_arimax$mean
lower_uni[(i-(96-1)+1),3]<-pred_arimax$lower[,2]
up_uni[(i-(96-1)+1),3]<-pred_arimax$upper[,2]
}
```


```{r, warning=FALSE}
#VECM
for(i in 96:(sample-1)){
all_series<-ts(data_pred[1:i,c('Renixx','Energy_i','Oil_p',"Energy_s")],start=c(2015,1),frequency=12)
#lag order
var <- VARselect(all_series, type = "both", lag.max = 12, season = 12)
p<-var$selection["FPE(n)"]
#Estimation of the VAR
var_all = VAR(all_series,p, season = 12,type = 'both') #3 for cointegration
#Residuals checks
res<-matrix(c(var_all[["varresult"]][["Renixx"]][["residuals"]],var_all[["varresult"]][["Energy_i"]][["residuals"]],var_all[["varresult"]][["Energy_s"]][["residuals"]],var_all[["varresult"]][["Oil_p"]][["residuals"]]), ncol = 4)
mvshapiro_test(res)
vars::arch.test(var_all,multivariate.only = TRUE)   
normality.test(var_all,multivariate.only = TRUE)  
serial.test(var_all, type = "PT.asymptotic",lags.pt = 12)
#Cointegration test
nlags=max((p-1),2)
jotest_all=ca.jo(all_series, type="eigen", K=nlags, ecdet="trend", spec= "transitory", season = 12)
summary(jotest_all)
jotest_all=ca.jo(all_series, type="trace", K=nlags, ecdet="trend", spec= "transitory", season = 12)
summary(jotest_all)
#Cointegration level
print(sum(jotest_all@teststat>jotest_all@cval[,2]))
#VECM
y.VEC <- cajorls(jotest_all, r=sum(jotest_all@teststat>jotest_all@cval[,2]))
y.VEC
summary(y.VEC$rlm)
#VECM to VAR
v0.VAR <- vec2var(jotest_all, r = sum(jotest_all@teststat>jotest_all@cval[,2]))
v0.VAR
#IRF
impresp <- irf(v0.VAR)
fevd(v0.VAR)$Renixx
#Probability forecasts
pred_var<-predict(v0.VAR, n.ahead = 1)
predictions_uni[(i-96+1),4]<-pred_var$fcst$Renixx[,1]
lower_uni[(i-96+1),4]<-pred_var$fcst$Renixx[,2]
up_uni[(i-96+1),4]<-pred_var$fcst$Renixx[,3]
}
```


```{r, warning=FALSE}
#ANN
all_series<-ts(data_pred2,start=c(2015,1),frequency=12)
for(i in (96-1):(sample-1-1)){
ann_rsme<-c()
pred_ann_c<-c()
best_params_ann = 0
best_score = 0
count<-
j<-round(i*0.8)
count<-1
#Validation set
for(dec in c(0,0.1,0.2,0.3,0.4,0.5)){
  for(rep in c(20)){
Ann<-nnetar(all_series[1:j,1],frequency = 12,decay=dec,repeats = rep)
pred_ann_c <- as.numeric(forecast::forecast(Ann, PI=TRUE,h=length((j+1):i))$mean)
ann_rsme <- Metrics::rmse(all_series[((j+1):i),c('Renixx')], pred_ann_c)
if(count == 1){
            best_params_ann = c(dec,rep)
            best_score = ann_rsme
            count = count + 1
            }
else if(ann_rsme < best_score){
            best_params_ann = c(dec,rep)
            best_score = ann_rsme
        }
}
}
#Final model
Ann<-nnetar(ts(all_series[1:i,1],frequency = 1),repeats = best_params_ann[2],decay=best_params_ann[1],lambda='auto')
#Probability forecasts
pred_ann<-forecast::forecast(Ann, PI=TRUE,h=1)
predictions_uni[(i-(96-1)+1),5]<-pred_ann$mean
lower_uni[(i-(96-1)+1),5]<-pred_ann$lower[,2]
up_uni[(i-(96-1)+1),5]<-pred_ann$upper[,2]
print(i)
}
```

Below, the metrics of the model are reported, along with some robustness checks.

```{r, warning=FALSE}
#SMAPE
Metrics::smape(predictions_uni[,1],data_pred0$Renixx)*100
Metrics::smape(predictions_uni[,2],data_pred0$Renixx)*100
Metrics::smape(predictions_uni[,3],data_pred0$Renixx)*100
Metrics::smape(predictions_uni[,4],data_pred0$Renixx)*100
Metrics::smape(predictions_uni[,5],data_pred0$Renixx)*100
#RMSE
Metrics::rmse(predictions_uni[,1],data_pred0$Renixx)
Metrics::rmse(predictions_uni[,2],data_pred0$Renixx)
Metrics::rmse(predictions_uni[,3],data_pred0$Renixx)
Metrics::rmse(predictions_uni[,4],data_pred0$Renixx)
Metrics::rmse(predictions_uni[,5],data_pred0$Renixx)
#Covarage Probability
sum(lower_uni[,1]<data_pred0$Renixx&data_pred0$Renixx<up_uni[,1])
sum(lower_uni[,2]<data_pred0$Renixx&data_pred0$Renixx<up_uni[,2])
sum(lower_uni[,3]<data_pred0$Renixx&data_pred0$Renixx<up_uni[,3])
sum(lower_uni[,4]<data_pred0$Renixx&data_pred0$Renixx<up_uni[,4])
sum(lower_uni[,5]<data_pred0$Renixx&data_pred0$Renixx<up_uni[,5])
#Mean Length
mean(up_uni[,1]-lower_uni[,1])
mean(up_uni[,2]-lower_uni[,2])
mean(up_uni[,3]-lower_uni[,3])
mean(up_uni[,4]-lower_uni[,4])
mean(up_uni[,5]-lower_uni[,5])
```
```{r, warning=FALSE}
#DM test
m<-predictions_uni-data_pred0$Renixx
dm.test(m[,1],m[,3], alternative =  "greater",h=1, power = 2,varestimator = 'bartlett')
dm.test(m[,4],m[,3], alternative =  "greater",h=1, power = 2,varestimator = 'bartlett')
dm.test(m[,5],m[,3], alternative =  "greater",h=1, power = 2,varestimator = 'bartlett')
#Theil's U
TheilU(data_pred0$Renixx,predictions_uni[,1])
TheilU(data_pred0$Renixx,predictions_uni[,3])
TheilU(data_pred0$Renixx,predictions_uni[,4])
TheilU(data_pred0$Renixx,predictions_uni[,5])
```

Although the ARIMAX model incorporating both text variables and oil prices exhibits the best performance in terms of SMAPE and RMSE, there is no clear evidence of its superior performance compared to the competitors.

```{r, warning=FALSE}
#Plot
data_pred$Date<-ymd(Energy_ipred$Time[133:240])
ggplot(data_pred[65:sample,], 
       aes(x =Date, 
           y = Renixx),
) +
  geom_line(aes(y=c(data_pred$Renixx[65:96],predictions_uni[,3]),color='Prediction'))+ 
geom_ribbon(aes(ymin=c(data_pred$Renixx[65:96],lower_uni[,3]), ymax=c(data_pred$Renixx[65:96],up_uni[,3])), alpha=0.1, fill = "green", 
              color = "green", linetype = "dotted")+
   geom_line(aes(color='Real data'))+
  labs(title = 'ARIMAX,one step ahead')+xlab('Time')+ylab('Log-price')+
  scale_color_manual(name='Legend',breaks=c('Real data', 'Prediction'),
                     values=c('Real data'='black', 'Prediction'='darkgreen'))
```

The same procedure is conducted using a multi-step ahead approach. Given the increased uncertainty in forecasting an entire year, the dataset is adjusted to encompass the years 2005-2022. Moreover, a categorical variable is incorporated into all models to identify potential bubble stages (0 for no bubble, 1 for bubble rise, and 2 for bubble decline). So, the model used in the analysis are the following ones,

*ARIMAX

*VECM

*NNETAR

```{r, warning=FALSE}
#Dataset
Data_VECM<-as.data.frame(log(renixx_m$close))
colnames(Data_VECM)[1]<-'Renixx'
#Energy index
Data_VECM$Energy_i<-log(Energy_i$Absolute.Google.Search.Volume)
#Energy share
Data_VECM$Energy_s<-log(Energy_s$Absolute.Google.Search.Volume)
#Oil price
Data_VECM$Oil_p<-log(Oil_m$Price)
Data_VECM$Dummy1<-c(rep(1,36),rep(0,59),rep(0,83),rep(1,38))
Data_VECM$Dummy2<-c(rep(0,36),rep(1,59),rep(0,83),rep(0,38))
#Realized dataset
Energy_spred <- read.csv("Google Trends/Energy_shares.csv", header=TRUE, comment.char="#")
Energy_ipred <- read.csv("Google Trends/Energy_index.csv", header=TRUE, comment.char="#")
Oil_pred <- read.csv("Predictions/Oil_pred.csv", header=TRUE, comment.char="#")
Oil_pred$Date <- dmy(Oil_pred$Date)
Month <- as.Date(cut(Oil_pred$Date, "month"))
Oil_predm <- aggregate(Price ~ Month, Oil_pred, mean)
Oil_predm<-Oil_predm[217:228,]
Renixx_pred <- read.csv("Predictions/Renixx_pred.csv", header=TRUE, comment.char="#")
Renixx_pred$date <- ymd(Renixx_pred$date)
Month <- as.Date(cut(Renixx_pred$date, "month"))
Renixx_predm <- aggregate(close ~ Month, Renixx_pred, mean)
data_pred0<-data.frame(log(Renixx_predm$close),log(Energy_ipred[229:240,3]),log(Oil_predm$Price),log(Energy_spred[229:240,3]),rep(0,12),rep(1,12))
colnames(data_pred0)<-c('Renixx','Energy_i','Oil_p',"Energy_s",'Dummy1','Dummy2')
data_pred<-rbind(Data_VECM[c(1:216),c('Renixx','Energy_i','Oil_p',"Energy_s",'Dummy1','Dummy2')],data_pred0)
rownames(data_pred)<-NULL
```

```{r, warning=FALSE}
#Parameter setting
iteration<-12
models<-3
sample<-length(data_pred[,1])
predictions_multi<-as.data.frame(matrix(nrow=iteration,ncol=models))
colnames(predictions_multi)<-c('ARIMA','VAR','NNETAR')
up_multi<-as.data.frame(matrix(nrow=iteration,ncol=models))
colnames(up_multi)<-c('ARIMA','VAR','NNETAR')
lower_multi<-as.data.frame(matrix(nrow=iteration,ncol=models))
colnames(lower_multi)<-c('ARIMA','VAR','NNETAR')
```

```{r, warning=FALSE}
#ARIMA+dummy
all_series<-ts(data_pred,start=c(2005,1),frequency=12)
#Dummy variables
exo<-as.matrix(data_pred[1:216,c('Dummy1','Dummy2')],ncol=2,nrow=216)
colnames(exo)<-c('exo1','exo2')
#ARIMA+dummy
arimad<-auto.arima(all_series[1:216,c('Renixx')],seasonal = TRUE, xreg=exo)
#New dummy variables
new<-matrix(c(rep(0,12),rep(1,12)),ncol=2,nrow=12)
colnames(new)<-c('exo1','exo2')
#Predictions
pred_arimad<-forecast::forecast(arimad,xreg=new,h=12)
predictions_multi[,1]<-pred_arimad$mean
lower_multi[,1]<-pred_arimad$lower[,2]
up_multi[,1]<-pred_arimad$upper[,2]
```

```{r, warning=FALSE}
#VECM
all_series<-ts(data_pred[1:216,c('Renixx','Energy_i','Oil_p',"Energy_s")],start=c(2005,1),frequency=12)
#Model selection
var <- VARselect(all_series, type = "both", lag.max = 12, season = 12)
p<-var$selection["FPE(n)"]
exo<-as.matrix(data_pred[1:216,c('Dummy1','Dummy2')],ncol=2,nrow=11)
colnames(exo)<-c('exo1','exo2')
#Estimation
var_all = VAR(all_series,p, season = 12,type = 'both',exogen=exo) #3 for cointegration
#Residual checks
res<-matrix(c(var_all[["varresult"]][["Renixx"]][["residuals"]],var_all[["varresult"]][["Energy_i"]][["residuals"]],var_all[["varresult"]][["Energy_s"]][["residuals"]],var_all[["varresult"]][["Oil_p"]][["residuals"]]), ncol = 4)
mvshapiro_test(res)
vars::arch.test(var_all,multivariate.only = TRUE)   
normality.test(var_all,multivariate.only = TRUE)  
serial.test(var_all, type = "PT.asymptotic",lags.pt = 12)
#Cointegration
nlags=max(3,p)-1
jotest_all=ca.jo(all_series, type="eigen", K=nlags, ecdet="trend", spec= "transitory", season = 12,dumvar=exo)
summary(jotest_all)
jotest_all=ca.jo(all_series, type="trace", K=nlags, ecdet="trend", spec= "transitory", season = 12,dumvar=exo)
summary(jotest_all)
#Cointegration level
print(sum(jotest_all@teststat>jotest_all@cval[,2]))
#VECM
y.VEC <- cajorls(jotest_all, r=sum(jotest_all@teststat>jotest_all@cval[,2]))
y.VEC
summary(y.VEC$rlm)
#VECM to VAR
v0.VAR <- vec2var(jotest_all, r = sum(jotest_all@teststat>jotest_all@cval[,2]))
v0.VAR
#Probability forecasts
exo<-matrix(c(rep(0,12),rep(1,12)),ncol=2,nrow=12)
colnames(exo)<-c('exo1','exo2')
pred_var<-predict(v0.VAR, n.ahead = 12, dumvar=exo)
predictions_multi[,2]<-pred_var$fcst$Renixx[,1]
lower_multi[,2]<-pred_var$fcst$Renixx[,2]
up_multi[,2]<-pred_var$fcst$Renixx[,3]
```

```{r, warning=FALSE}
#ANN
data_pred2<-data_pred[1:216,c('Renixx','Energy_i')]
all_series<-ts(data_pred2,start=c(2005,2),frequency=12)
ann_rsme<-c()
pred_ann_c<-c()
best_params_ann = 0
best_score = 0
j<-round(216*0.8)
count<-1
#Validation set
exo<-as.matrix(data_pred[1:216,c('Dummy1','Dummy2')],ncol=2,nrow=216)
colnames(exo)<-c('exo1','exo2')
for(dec in c(0,0.1,0.2,0.3,0.4,0.5)){
  for(rep in c(20)){
Ann<-nnetar(all_series[1:j,1],frequency = 12,decay=dec,repeats = rep, xreg = exo[1:j])
pred_ann_c <- as.numeric(forecast::forecast(Ann, PI=TRUE,h=length((j+1):216),xreg=exo[(j+1):216])$mean)
ann_rsme <- Metrics::rmse(all_series[((j+1):216),c('Renixx')], pred_ann_c)
if(count == 1){
            best_params_ann = c(dec,rep)
            best_score = ann_rsme
            count = count + 1
            }
else if(ann_rsme < best_score){
            best_params_ann = c(dec,rep)
            best_score = ann_rsme
        }
}
}
#New dummy variables
new<-matrix(c(rep(0,12),rep(1,12)),ncol=2,nrow=12)
colnames(new)<-c('exo1','exo2')
#Final model
Ann<-nnetar(ts(all_series[1:216,1],frequency = 1),repeats = best_params_ann[2],decay=best_params_ann[1],lambda='auto',xreg=exo)
pred_ann<-forecast::forecast(Ann, PI=TRUE, h=12,xreg=new)
predictions_multi[,3]<-pred_ann$mean
lower_multi[,3]<-pred_ann$lower[,2]
up_multi[,3]<-pred_ann$upper[,2]
```

As previously, the primary metrics along with robustness checks are presented below.

```{r, warning=FALSE}
#SMAPE
Metrics::smape(predictions_multi[,1],data_pred0$Renixx)*100
Metrics::smape(predictions_multi[,2],data_pred0$Renixx)*100
Metrics::smape(predictions_multi[,3],data_pred0$Renixx)*100
#RMSE
Metrics::rmse(predictions_multi[,1],data_pred0$Renixx)
Metrics::rmse(predictions_multi[,2],data_pred0$Renixx)
Metrics::rmse(predictions_multi[,3],data_pred0$Renixx)
```

```{r, warning=FALSE}
#DM
m<-predictions_multi-data_pred0$Renixx
dm.test(m[,1],m[,2], alternative =  "greater",h=1, power = 2,varestimator = 'bartlett')
dm.test(m[,3],m[,2], alternative =  "greater",h=1, power = 2,varestimator = 'bartlett')
#Theil's U
TheilU(data_pred0$Renixx,predictions_multi[,1])
TheilU(data_pred0$Renixx,predictions_multi[,2])
TheilU(data_pred0$Renixx,predictions_multi[,3])
```

In the multi-step ahead forecast exercise, there is a clear supremacy of the VECM over the two univariate competitors. This highlights not only the usefulness of text variables but also the significance of past bubble dynamics.

```{r, warning=FALSE}
#Plot
data_pred$Date<-ymd(Energy_ipred$Time[13:240])
ggplot(data_pred[185:sample,], 
       aes(x =Date, 
           y = Renixx),
) +
  geom_line(aes(y=c(data_pred$Renixx[185:216],predictions_multi[,2]),color='Prediction'))+ 
geom_ribbon(aes(ymin=c(data_pred$Renixx[185:216],lower_multi[,2]), ymax=c(data_pred$Renixx[185:216],up_multi[,2])), alpha=0.1, fill = "green", 
              color = "green", linetype = "dotted")+
   geom_line(aes(color='Real data'))+
  labs(title = 'VECM, multi-step ahead')+xlab('Time')+ylab('Log-price')+
  scale_color_manual(name='Legend',breaks=c('Real data', 'Prediction'),
                     values=c('Real data'='black', 'Prediction'='darkgreen'))
```

#Finance implications

The following chuncks report on the potential propagation effects of the Renixx index on the stability of the financial system (OFR).

```{r, warning=FALSE}
all_series<-ts(Data_3[c(1:216),c('Renixx','OFR','Oil_p')],start=c(2005,1), end=c(2022,12),frequency=12)

var <- VARselect(all_series, type = "none", lag.max = 12, season = 12)
var$selection["FPE(n)"]

var_OFR <- VAR(all_series,1, season = 12,type = 'none')
summary(var_OFR)
causality(var_OFR, cause = "OFR")
causality(var_OFR, cause = "Renixx")
causality(var_OFR, cause = "Oil_p")
xtable(var_OFR$varresult$OFR)
```

```{r, warning=FALSE}
vars::arch.test(var_OFR,multivariate.only = TRUE)   
normality.test(var_OFR,multivariate.only = TRUE)  
serial.test(var_OFR, type = "BG",lags.bg = 12)
plot(stability(var_OFR), nc = 2)

impresp <- irf(var_OFR,impulse = 'Renixx', response='OFR')
impresp$irf$Renixx <- -impresp$irf$Renixx #negative shock
impresp$Lower$Renixx <- -impresp$Lower$Renixx
impresp$Upper$Renixx <- -impresp$Upper$Renixx
plot(impresp, main='Impulse Response Function from RENIXX, negative shock',ylab='FSI')

plot(fevd(var_OFR),nr = 2)
fevd(var_OFR)
```


The results highlight a Granger causality between both the oil price and the Renixx index concerning the OFR. This underscores significant findings for policymakers, who must consider green assets as potential triggers of Climate Minsky moments.
